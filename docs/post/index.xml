<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Posts on cfh::blog</title>
    <link>https://c-f-h.github.io/post/</link>
    <description>Recent content in Posts on cfh::blog</description>
    <generator>Hugo -- 0.145.0</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 08 May 2025 21:56:00 +0200</lastBuildDate>
    <atom:link href="https://c-f-h.github.io/post/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Actor-Critic Algorithms</title>
      <link>https://c-f-h.github.io/post/actor-critic/</link>
      <pubDate>Thu, 08 May 2025 21:56:00 +0200</pubDate>
      <guid>https://c-f-h.github.io/post/actor-critic/</guid>
      <description>&lt;p&gt;After &lt;a href=&#34;https://c-f-h.github.io/post/implementing-rwb/&#34;&gt;implementing and evaluating&lt;/a&gt; REINFORCE with baseline,
we found that it can produce strong models, but takes a long time to learn an accurate
value function due to the high variance of the
&lt;a href=&#34;https://c-f-h.github.io/post/reinforce-with-baseline/#monte-carlo-sampling&#34;&gt;Monte Carlo samples&lt;/a&gt;.
In this post, we&amp;rsquo;ll look at Actor-Critic methods, and in particular the
Advantage Actor-Critic (A2C) algorithm&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;,
a synchronous version of the earlier Asynchronous Advantage Actor-Critic (A3C) method,
as a way to remedy this.&lt;/p&gt;
&lt;p&gt;Before we start, recall that we introduced a &lt;a href=&#34;https://c-f-h.github.io/post/reinforce-with-baseline/#the-value-network&#34;&gt;value network&lt;/a&gt; as a component of our model; this remains the same for A2C, and in fact
we don&amp;rsquo;t need to modify the network architecture at all to use this newer algorithm.
Our model still consists of a residual CNN backbone, a policy head and a value head.
The value head serves as the &amp;ldquo;critic,&amp;rdquo; whereas the policy head is the &amp;ldquo;actor&amp;rdquo;.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Implementing and Evaluating REINFORCE with Baseline</title>
      <link>https://c-f-h.github.io/post/implementing-rwb/</link>
      <pubDate>Thu, 01 May 2025 23:05:00 +0200</pubDate>
      <guid>https://c-f-h.github.io/post/implementing-rwb/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://c-f-h.github.io/post/reinforce-with-baseline/&#34;&gt;Having introduced&lt;/a&gt; REINFORCE with baseline on a
conceptual level, let&amp;rsquo;s implement it for our Connect 4-playing CNN model.&lt;/p&gt;
&lt;div class=&#34;example-code&#34;&gt;
  &lt;div class=&#34;header&#34;&gt;
    &lt;svg viewBox=&#34;0 0 16 16&#34; fill=&#34;none&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34;&gt;
  &lt;path d=&#34;M5.79 1.574h3.866c.14 0 .252.11.252.246v5.186a.25.25 0 01-.252.246H6.344c-.975 0-1.766.77-1.766 1.72v1.162a.25.25 0 01-.253.243H1.867a.25.25 0 01-.253-.246V6.177a.25.25 0 01.252-.246H7.98c.418 0 .757-.33.757-.737a.747.747 0 00-.757-.738H5.537V1.82a.25.25 0 01.253-.246zm5.632 2.592V1.82c0-.95-.79-1.72-1.766-1.72H5.79c-.976 0-1.767.77-1.767 1.72v2.636H1.867C.89 4.456.1 5.226.1 6.176v3.955c0 .95.79 1.72 1.766 1.72h2.46c.085 0 .17-.006.252-.017v2.346c0 .95.79 1.72 1.766 1.72h3.866c.976 0 1.767-.77 1.767-1.72v-2.636h2.156c.976 0 1.767-.77 1.767-1.72V5.868c0-.95-.79-1.72-1.767-1.72h-2.458c-.086 0-.17.005-.253.017zm-5.33 5.974V8.994a.25.25 0 01.252-.246h3.312c.976 0 1.766-.77 1.766-1.72V5.866a.25.25 0 01.253-.243h2.458c.14 0 .253.11.253.246v3.954a.25.25 0 01-.252.246H8.02a.747.747 0 00-.757.737c0 .408.339.738.757.738h2.442v2.636a.25.25 0 01-.253.246H6.344a.25.25 0 01-.252-.246v-4.04z&#34; fill=&#34;currentColor&#34;/&gt;
&lt;/svg&gt;
    &lt;span&gt;Runnable Example&lt;/span&gt;&lt;/div&gt;
  &lt;a href=&#34;https://github.com/c-f-h/connect-zero/blob/main/train/example3-rwb.py&#34; target=&#34;_blank&#34;&gt;
    connect-zero/train/example3-rwb.py
  &lt;/a&gt;
&lt;/div&gt;
&lt;h2 id=&#34;adding-the-value-head&#34;&gt;Adding the value head&lt;/h2&gt;
&lt;p&gt;In the constructor of the &lt;a href=&#34;https://c-f-h.github.io/post/model-design/&#34;&gt;&lt;code&gt;Connect4CNN&lt;/code&gt; model class&lt;/a&gt;,
we set up the new network for estimating the board state value \(v(s)\)
which will consume the same 448 downsampled features that the policy head receives:&lt;/p&gt;</description>
    </item>
    <item>
      <title>REINFORCE with Baseline</title>
      <link>https://c-f-h.github.io/post/reinforce-with-baseline/</link>
      <pubDate>Tue, 29 Apr 2025 08:42:00 +0200</pubDate>
      <guid>https://c-f-h.github.io/post/reinforce-with-baseline/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://c-f-h.github.io/post/model-design/&#34;&gt;In the previous post&lt;/a&gt;, we introduced a stronger model
but observed that it&amp;rsquo;s quite challenging to achieve
a high level of play with &lt;a href=&#34;https://c-f-h.github.io/post/the-reinforce-algorithm/&#34;&gt;basic REINFORCE&lt;/a&gt;,
due to the high variance and noisy gradients of the algorithm which often lead to unstable
learning and slow convergence.
Our first step towards more advanced algorithms is a modification called
&amp;ldquo;REINFORCE with baseline&amp;rdquo; (see, e.g.,
&lt;a href=&#34;https://proceedings.neurips.cc/paper_files/paper/1999/file/464d828b85b0bed98e80ade0a5c43b0f-Paper.pdf&#34;&gt;Sutton et al. (2000)&lt;/a&gt;).&lt;/p&gt;
&lt;h2 id=&#34;the-value-network&#34;&gt;The value network&lt;/h2&gt;
&lt;p&gt;Given a board state \(s\), &lt;a href=&#34;https://c-f-h.github.io/post/basic-setup-and-play/&#34;&gt;recall that&lt;/a&gt; our model
currently outputs seven raw logits which are then
transformed via softmax into the probability distribution \(p(s)\) over the seven possible
moves. Many advanced algorithms in RL assume that our network also outputs
a second piece of information: the &lt;strong&gt;value&lt;/strong&gt; \(v(s)\), a number between -1 and 1 which,
roughly speaking, gives an estimate of how confident the model is in winning from the
current position.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Model Design for Connect 4</title>
      <link>https://c-f-h.github.io/post/model-design/</link>
      <pubDate>Mon, 28 Apr 2025 22:30:00 +0200</pubDate>
      <guid>https://c-f-h.github.io/post/model-design/</guid>
      <description>&lt;p&gt;With the &lt;a href=&#34;https://c-f-h.github.io/post/random-punisher/&#34;&gt;fearsome RandomPunisher&lt;/a&gt; putting our
&lt;a href=&#34;https://c-f-h.github.io/post/entropy-regularization/&#34;&gt;first Connect 4 toy model&lt;/a&gt;
in its place, it&amp;rsquo;s time to design something that stands a chance.&lt;/p&gt;
&lt;h2 id=&#34;a-design-based-on-cnns&#34;&gt;A design based on CNNs&lt;/h2&gt;
&lt;p&gt;It&amp;rsquo;s standard practice for board-game playing neural networks to have at least a few
&lt;strong&gt;convolutional neural network (CNN)&lt;/strong&gt; layers at the initial inputs. This shouldn&amp;rsquo;t come as
a surprise: the board is a regular grid, much like an image, and CNNs are strong performers
in image processing. In our case, it will allow the model to learn features like
&amp;ldquo;here are three of my pieces in a diagonal downward row&amp;rdquo; which are then automatically
applied to every position on the board, rather than having to re-learn these features
individually at each board position.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Introducing a Benchmark Opponent</title>
      <link>https://c-f-h.github.io/post/random-punisher/</link>
      <pubDate>Sat, 26 Apr 2025 09:50:00 +0200</pubDate>
      <guid>https://c-f-h.github.io/post/random-punisher/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://c-f-h.github.io/post/entropy-regularization/&#34;&gt;Last time&lt;/a&gt; we saw how the entropy bonus
enables self-play training without running into policy collapse.
However, the model we trained was quite small and probably not capable of very strong play.
Before we dive into the details of an improved model architecture, it would be very helpful
to have a decent, fixed benchmark to gauge our progress.&lt;/p&gt;
&lt;h2 id=&#34;a-benchmark-opponent&#34;&gt;A benchmark opponent&lt;/h2&gt;
&lt;p&gt;The only model with fixed performance we have right now is the &lt;code&gt;RandomPlayer&lt;/code&gt; from the
&lt;a href=&#34;https://c-f-h.github.io/post/basic-setup-and-play/&#34;&gt;basic setup post&lt;/a&gt;. Obviously, that&amp;rsquo;s not a challenging
bar to clear. But it turns out that with some small tweaks, we can turn the fully random
player into a formidable opponent for our starter models.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Entropy Regularization</title>
      <link>https://c-f-h.github.io/post/entropy-regularization/</link>
      <pubDate>Thu, 24 Apr 2025 20:15:00 +0200</pubDate>
      <guid>https://c-f-h.github.io/post/entropy-regularization/</guid>
      <description>&lt;p&gt;Based on our &lt;a href=&#34;https://c-f-h.github.io/post/on-entropy/&#34;&gt;discussion on entropy&lt;/a&gt;, our plan is to implement
entropy regularization via an entropy bonus in our loss function.&lt;/p&gt;
&lt;div class=&#34;example-code&#34;&gt;
  &lt;div class=&#34;header&#34;&gt;
    &lt;svg viewBox=&#34;0 0 16 16&#34; fill=&#34;none&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34;&gt;
  &lt;path d=&#34;M5.79 1.574h3.866c.14 0 .252.11.252.246v5.186a.25.25 0 01-.252.246H6.344c-.975 0-1.766.77-1.766 1.72v1.162a.25.25 0 01-.253.243H1.867a.25.25 0 01-.253-.246V6.177a.25.25 0 01.252-.246H7.98c.418 0 .757-.33.757-.737a.747.747 0 00-.757-.738H5.537V1.82a.25.25 0 01.253-.246zm5.632 2.592V1.82c0-.95-.79-1.72-1.766-1.72H5.79c-.976 0-1.767.77-1.767 1.72v2.636H1.867C.89 4.456.1 5.226.1 6.176v3.955c0 .95.79 1.72 1.766 1.72h2.46c.085 0 .17-.006.252-.017v2.346c0 .95.79 1.72 1.766 1.72h3.866c.976 0 1.767-.77 1.767-1.72v-2.636h2.156c.976 0 1.767-.77 1.767-1.72V5.868c0-.95-.79-1.72-1.767-1.72h-2.458c-.086 0-.17.005-.253.017zm-5.33 5.974V8.994a.25.25 0 01.252-.246h3.312c.976 0 1.766-.77 1.766-1.72V5.866a.25.25 0 01.253-.243h2.458c.14 0 .253.11.253.246v3.954a.25.25 0 01-.252.246H8.02a.747.747 0 00-.757.737c0 .408.339.738.757.738h2.442v2.636a.25.25 0 01-.253.246H6.344a.25.25 0 01-.252-.246v-4.04z&#34; fill=&#34;currentColor&#34;/&gt;
&lt;/svg&gt;
    &lt;span&gt;Runnable Example&lt;/span&gt;&lt;/div&gt;
  &lt;a href=&#34;https://github.com/c-f-h/connect-zero/blob/main/train/example2-entropy.py&#34; target=&#34;_blank&#34;&gt;
    connect-zero/train/example2-entropy.py
  &lt;/a&gt;
&lt;/div&gt;
&lt;h2 id=&#34;implementing-the-entropy-bonus&#34;&gt;Implementing the entropy bonus&lt;/h2&gt;
&lt;p&gt;The formula for entropy which we have to implement,&lt;/p&gt;</description>
    </item>
    <item>
      <title>On Entropy</title>
      <link>https://c-f-h.github.io/post/on-entropy/</link>
      <pubDate>Wed, 23 Apr 2025 20:57:00 +0200</pubDate>
      <guid>https://c-f-h.github.io/post/on-entropy/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://c-f-h.github.io/post/policy-collapse/&#34;&gt;The last time&lt;/a&gt;, we ran our first self-play training loop
on a simple MLP model and observed catastrophic policy collapse. Let&amp;rsquo;s first understand
some of the math behind what happened, and then how to combat it.&lt;/p&gt;
&lt;h2 id=&#34;what-is-entropy&#34;&gt;What is entropy?&lt;/h2&gt;
&lt;p&gt;Given a probability distribution \(p=(p_1,\ldots,p_C)\)
over a number of categories \(i=1,\ldots,C\), such as the distribution over the columns our
Connect 4 model outputs for a given board state, entropy measures the &amp;ldquo;amount of
randomness&amp;rdquo; and is defined as&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>A First Training Run and Policy Collapse</title>
      <link>https://c-f-h.github.io/post/policy-collapse/</link>
      <pubDate>Mon, 21 Apr 2025 17:45:00 +0200</pubDate>
      <guid>https://c-f-h.github.io/post/policy-collapse/</guid>
      <description>&lt;p&gt;With the &lt;a href=&#34;https://c-f-h.github.io/post/the-reinforce-algorithm/&#34;&gt;REINFORCE algorithm&lt;/a&gt; under our belt,
we can finally attempt to start training some models for
&lt;a href=&#34;https://c-f-h.github.io/post/connect-zero/&#34;&gt;Connect 4&lt;/a&gt;.
However, as we&amp;rsquo;ll see, there are still some hurdles in our way before we get anywhere.
It&amp;rsquo;s good to set your expectations accordingly because rarely if ever do things go
smoothly the first time in RL.&lt;/p&gt;
&lt;div class=&#34;example-code&#34;&gt;
  &lt;div class=&#34;header&#34;&gt;
    &lt;svg viewBox=&#34;0 0 16 16&#34; fill=&#34;none&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34;&gt;
  &lt;path d=&#34;M5.79 1.574h3.866c.14 0 .252.11.252.246v5.186a.25.25 0 01-.252.246H6.344c-.975 0-1.766.77-1.766 1.72v1.162a.25.25 0 01-.253.243H1.867a.25.25 0 01-.253-.246V6.177a.25.25 0 01.252-.246H7.98c.418 0 .757-.33.757-.737a.747.747 0 00-.757-.738H5.537V1.82a.25.25 0 01.253-.246zm5.632 2.592V1.82c0-.95-.79-1.72-1.766-1.72H5.79c-.976 0-1.767.77-1.767 1.72v2.636H1.867C.89 4.456.1 5.226.1 6.176v3.955c0 .95.79 1.72 1.766 1.72h2.46c.085 0 .17-.006.252-.017v2.346c0 .95.79 1.72 1.766 1.72h3.866c.976 0 1.767-.77 1.767-1.72v-2.636h2.156c.976 0 1.767-.77 1.767-1.72V5.868c0-.95-.79-1.72-1.767-1.72h-2.458c-.086 0-.17.005-.253.017zm-5.33 5.974V8.994a.25.25 0 01.252-.246h3.312c.976 0 1.766-.77 1.766-1.72V5.866a.25.25 0 01.253-.243h2.458c.14 0 .253.11.253.246v3.954a.25.25 0 01-.252.246H8.02a.747.747 0 00-.757.737c0 .408.339.738.757.738h2.442v2.636a.25.25 0 01-.253.246H6.344a.25.25 0 01-.252-.246v-4.04z&#34; fill=&#34;currentColor&#34;/&gt;
&lt;/svg&gt;
    &lt;span&gt;Runnable Example&lt;/span&gt;&lt;/div&gt;
  &lt;a href=&#34;https://github.com/c-f-h/connect-zero/blob/main/train/example1-collapse.py&#34; target=&#34;_blank&#34;&gt;
    connect-zero/train/example1-collapse.py
  &lt;/a&gt;
&lt;/div&gt;
&lt;h2 id=&#34;a-simple-mlp-model&#34;&gt;A simple MLP model&lt;/h2&gt;
&lt;p&gt;As a fruitfly of Connect 4-playing models, let&amp;rsquo;s start with a simple multilayer perceptron
(MLP) model that follows the &lt;a href=&#34;https://c-f-h.github.io/post/basic-setup-and-play/&#34;&gt;model protocol&lt;/a&gt; we
outlined earlier: that means that it has an input layer taking a 6x7 &lt;code&gt;int8&lt;/code&gt; board state
tensor, a few simple hidden layers consisting of just a linear layer and a ReLU activation
function each, and an output layer of 7 neurons without any activation function&amp;mdash;that&amp;rsquo;s
exactly what we meant earlier when we said that the model should output raw logits.&lt;/p&gt;</description>
    </item>
    <item>
      <title>The REINFORCE Algorithm</title>
      <link>https://c-f-h.github.io/post/the-reinforce-algorithm/</link>
      <pubDate>Sun, 20 Apr 2025 20:29:21 +0200</pubDate>
      <guid>https://c-f-h.github.io/post/the-reinforce-algorithm/</guid>
      <description>&lt;p&gt;Let&amp;rsquo;s say we have a Connect 4-playing model and we let it
&lt;a href=&#34;https://c-f-h.github.io/post/basic-setup-and-play/&#34;&gt;play a couple of games&lt;/a&gt;.
(We haven&amp;rsquo;t really talked about model architecture until now, so for now just imagine a
simple multilayer perceptron with a few hidden layers which outputs 7 raw logits,
as discussed in the previous post.)&lt;/p&gt;
&lt;p&gt;As it goes in life, our model wins some and loses some. How do we make it
actually learn from its experiences? How does the magic happen?&lt;/p&gt;</description>
    </item>
    <item>
      <title>Basic Setup and Play</title>
      <link>https://c-f-h.github.io/post/basic-setup-and-play/</link>
      <pubDate>Sun, 20 Apr 2025 15:35:41 +0200</pubDate>
      <guid>https://c-f-h.github.io/post/basic-setup-and-play/</guid>
      <description>&lt;p&gt;Let&amp;rsquo;s get into a bit more technical detail on how our
&lt;a href=&#34;https://c-f-h.github.io/post/connect-zero/&#34;&gt;Connect 4-playing model&lt;/a&gt;
will be set up, and how a basic game loop works.
Throughout all code samples we&amp;rsquo;ll always assume the standard PyTorch imports:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;torch&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;torch.nn&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;nn&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;torch.nn.functional&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;F&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;board-state&#34;&gt;Board state&lt;/h2&gt;
&lt;p&gt;The current board state will be represented by a 6x7 PyTorch &lt;code&gt;int8&lt;/code&gt; tensor,
initially filled with zeros.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;board&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;torch&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;zeros&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;((&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ROWS&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;COLS&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;dtype&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;torch&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;int8&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;device&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;DEVICE&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The board is ordered such that &lt;code&gt;board[0, :]&lt;/code&gt; is the top row.
A non-empty cell is represented by +1 or -1. To simplify things, we always
represent the player whose move it currently is by +1, and the opponent by -1.
This way we don&amp;rsquo;t need any separate state to keep track of whose move it is.
After a move has been made, we simply flip the board by doing&lt;/p&gt;</description>
    </item>
    <item>
      <title>Connect-Zero: Reinforcement Learning from Scratch</title>
      <link>https://c-f-h.github.io/post/connect-zero/</link>
      <pubDate>Sun, 20 Apr 2025 13:12:41 +0200</pubDate>
      <guid>https://c-f-h.github.io/post/connect-zero/</guid>
      <description>&lt;p&gt;For a long time I&amp;rsquo;ve wanted to get deeper into reinforcement learning (RL), and the project
I finally settled on is teaching a neural network model
how to play the classic game &lt;strong&gt;Connect 4&lt;/strong&gt; (&lt;a href=&#34;https://www.youtube.com/watch?v=KN3nohBw_CE&#34;&gt;pretty sneaky, sis!&lt;/a&gt;).
Obviously, the name &amp;ldquo;Connect-Zero&amp;rdquo; is a cheeky nod to AlphaGo Zero
and AlphaZero by DeepMind.
I chose Connect 4 because it&amp;rsquo;s a simple game everyone knows how to play where we can
hope to achieve good results without expensive hardware and high training costs.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Connect 4</title>
      <link>https://c-f-h.github.io/post/connect-4/</link>
      <pubDate>Sun, 20 Apr 2025 09:29:36 +0200</pubDate>
      <guid>https://c-f-h.github.io/post/connect-4/</guid>
      <description>&lt;div id=&#34;game-container1&#34; class=&#34;connect4-container&#34;
    data-human=&#34;1&#34; data-cpu=&#34;2&#34;
    data-random-first-player=&#34;true&#34;
    data-onnx-model=&#34;export.onnx&#34;
&gt;&lt;/div&gt;
&lt;p&gt;The computer opponent is a neural network trained using reinforcement learning.
It was exported to ONNX and now runs right here in your browser.
See &lt;a href=&#34;https://c-f-h.github.io/post/connect-zero/&#34;&gt;Connect-Zero&lt;/a&gt; and the follow-up posts for details.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Training the First Model</title>
      <link>https://c-f-h.github.io/post/training-the-first-model/</link>
      <pubDate>Thu, 10 Apr 2025 20:29:11 +0200</pubDate>
      <guid>https://c-f-h.github.io/post/training-the-first-model/</guid>
      <description>&lt;p&gt;Now that we have plenty of &lt;a href=&#34;https://c-f-h.github.io/post/preparing-the-data/&#34;&gt;training data&lt;/a&gt;, we can load it into PyTorch and
start training a model.&lt;/p&gt;
&lt;h2 id=&#34;loading-the-data&#34;&gt;Loading the data&lt;/h2&gt;
&lt;p&gt;Since the binary file format we chose was so simple, it&amp;rsquo;s rather straightforward to write a &lt;code&gt;Dataset&lt;/code&gt; class which
reads it in:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;numpy&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;np&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;torch&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;torch.utils.data&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Dataset&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;DataLoader&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Subset&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;nc&#34;&gt;BinaryBezierDataset&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Dataset&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;s2&#34;&gt;&amp;#34;&amp;#34;&amp;#34;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;    Loads Bezier triangle data from a binary file into memory once.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;    Each record: 11 float32 coords, 32 uint8 bytes (packed 16x16 bitmap).
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;    &amp;#34;&amp;#34;&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;fm&#34;&gt;__init__&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;filename&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;device&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;input_dim&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;11&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nb&#34;&gt;super&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;fm&#34;&gt;__init__&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;filename&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;filename&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;input_dim&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;input_dim&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;coords_bytes&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;input_dim&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;np&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;dtype&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;np&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;float32&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;itemsize&lt;/span&gt;  &lt;span class=&#34;c1&#34;&gt;# 44&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;record_bytes&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;coords_bytes&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;32&lt;/span&gt;       &lt;span class=&#34;c1&#34;&gt;# 76 (coords + 16x16 bitmap = 256 bits)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;c1&#34;&gt;# Calculate number of samples from file size&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;file_size&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;os&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;path&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;getsize&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;filename&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;file_size&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;%&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;record_bytes&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;!=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;k&#34;&gt;raise&lt;/span&gt; &lt;span class=&#34;ne&#34;&gt;ValueError&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;sa&#34;&gt;f&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;File size &lt;/span&gt;&lt;span class=&#34;si&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;file_size&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt; not multiple of record size &lt;/span&gt;&lt;span class=&#34;si&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;record_bytes&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;num_samples&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;file_size&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;//&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;record_bytes&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;sa&#34;&gt;f&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;Found &lt;/span&gt;&lt;span class=&#34;si&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;num_samples&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt; samples in &lt;/span&gt;&lt;span class=&#34;si&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;filename&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;.&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;k&#34;&gt;with&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;open&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;filename&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;rb&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;f&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;n&#34;&gt;data&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;np&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;fromfile&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;f&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;dtype&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;np&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;uint8&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;count&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;file_size&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;data&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;data&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;reshape&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;num_samples&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;record_bytes&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;    &lt;span class=&#34;c1&#34;&gt;# reshape into records&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;c1&#34;&gt;# Extract coords (first 44 bytes = 11 floats)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;coords&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;data&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[:,&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;coords_bytes&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;view&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;np&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;float32&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;reshape&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;num_samples&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;input_dim&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;c1&#34;&gt;# Extract and unpack packed bitmaps (last 32 bytes)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;packed_bitmaps&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;data&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[:,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;coords_bytes&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;unpacked_bits&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;np&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;unpackbits&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;packed_bitmaps&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;axis&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;  &lt;span class=&#34;c1&#34;&gt;# (num_samples, 256)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;c1&#34;&gt;# The actual label is the maximum (0 or 1) over the bitmap bits&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;outputs&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;np&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;max&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;unpacked_bits&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;axis&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;     &lt;span class=&#34;c1&#34;&gt;# (num_samples,)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;c1&#34;&gt;# Convert to pytorch tensors and transfer to GPU if required&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x_tensor&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;torch&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;from_numpy&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;coords&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;float&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;to&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;device&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;   &lt;span class=&#34;c1&#34;&gt;# (num_samples, 11)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;y_tensor&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;torch&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;from_numpy&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;outputs&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;float&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;to&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;device&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;  &lt;span class=&#34;c1&#34;&gt;# (num_samples,)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;fm&#34;&gt;__len__&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;num_samples&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;fm&#34;&gt;__getitem__&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;idx&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x_tensor&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;idx&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt; &lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;y_tensor&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;idx&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;So far, so good. We are in the convenient position that our entire dataset fits quite comfortably into RAM or VRAM,
so we just load the entire dataset at once, extract the 11 triangle coordinates, unpack the bitmap and take its maximum
to get a binary 0/1 label which tells us whether the triangle self-intersects. This is a pretty straightforward
&lt;code&gt;DataSet&lt;/code&gt; which we can load into a &lt;code&gt;nn.DataLoader&lt;/code&gt; with the desired batch size and shuffling enabled to feed a
standard PyTorch training loop. It&amp;rsquo;s actually not very efficient to use it like this, but we&amp;rsquo;ll get to that in a later post.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Preparing the Data</title>
      <link>https://c-f-h.github.io/post/preparing-the-data/</link>
      <pubDate>Wed, 09 Apr 2025 20:57:38 +0200</pubDate>
      <guid>https://c-f-h.github.io/post/preparing-the-data/</guid>
      <description>&lt;p&gt;With the &lt;a href=&#34;https://c-f-h.github.io/post/refining-intersections/&#34;&gt;triangle self-intersection algorithm&lt;/a&gt; ready to go, we
can start gathering the training data for our machine learning setup. But first we have to think about how
exactly we want to represent it.&lt;/p&gt;
&lt;h2 id=&#34;canonical-triangles&#34;&gt;Canonical triangles&lt;/h2&gt;
&lt;p&gt;The &lt;a href=&#34;https://c-f-h.github.io/post/the-triangle-problem/&#34;&gt;curved triangles&lt;/a&gt; we work with are specified by six 3D vectors, so that
would mean 18 floating point numbers as our input data.
But an important insight is that whether a triangle intersects itself doesn&amp;rsquo;t change when we rotate it, translate it,
or uniformly scale it&amp;mdash;it&amp;rsquo;s well known that affine transformations of spline control points result in affine transformations of the surface itself.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Getting Accurate Intersections with Gauss-Newton</title>
      <link>https://c-f-h.github.io/post/refining-intersections/</link>
      <pubDate>Tue, 08 Apr 2025 08:33:00 +0200</pubDate>
      <guid>https://c-f-h.github.io/post/refining-intersections/</guid>
      <description>&lt;p&gt;In the &lt;a href=&#34;https://c-f-h.github.io/post/computing-intersections/&#34;&gt;last post&lt;/a&gt;, we found pairs of subtriangles of our
&lt;a href=&#34;https://c-f-h.github.io/post/the-triangle-problem/&#34;&gt;curved triangle&lt;/a&gt; which intersect.
The subtriangles were linear approximations, which means that the intersection points we found are also only approximate.
This might be good enough for our purposes, but in the interest of getting training data that&amp;rsquo;s as accurate as possible, we will
refine these intersections by projecting them onto the exact curved triangle.&lt;/p&gt;
&lt;p&gt;To be precise, we are looking for two distinct parameter pairs \((u_1, v_1)\) and \((u_2, v_2)\) within the triangle&amp;rsquo;s domain such that their mappings coincide,&lt;/p&gt;</description>
    </item>
    <item>
      <title>Computing Self-Intersections, the Geometric Way</title>
      <link>https://c-f-h.github.io/post/computing-intersections/</link>
      <pubDate>Mon, 07 Apr 2025 17:52:07 +0200</pubDate>
      <guid>https://c-f-h.github.io/post/computing-intersections/</guid>
      <description>&lt;p&gt;Before we can apply ML to the &lt;a href=&#34;https://c-f-h.github.io/post/the-triangle-problem/&#34;&gt;triangle problem&lt;/a&gt;, we need to be able to
compute self-intersections of a curved triangle in an accurate and efficient way so that we can generate enough training data.&lt;/p&gt;
&lt;p&gt;The basic approach is:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;#subdividing-the-triangle&#34;&gt;Subdivide&lt;/a&gt; the curved triangle into smaller subtriangles&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#finding-candidate-pairs-using-a-bounding-volume-hierarchy-bvh&#34;&gt;Find&lt;/a&gt; potentially intersecting pairs of subtriangles&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#finding-true-intersection-pairs&#34;&gt;Check&lt;/a&gt; for actual intersections among these candidate pairs&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;subdividing-the-triangle&#34;&gt;Subdividing the triangle&lt;/h2&gt;
&lt;p&gt;We split the original triangle into a list of sufficiently flat subtriangles by a simple recursive
procedure, starting with the full triangle &lt;code&gt;{(0,0), (1,0), (0,1)}&lt;/code&gt;:&lt;/p&gt;</description>
    </item>
    <item>
      <title>The Curved Triangle Problem</title>
      <link>https://c-f-h.github.io/post/the-triangle-problem/</link>
      <pubDate>Sun, 06 Apr 2025 21:06:14 +0200</pubDate>
      <guid>https://c-f-h.github.io/post/the-triangle-problem/</guid>
      <description>&lt;p&gt;As the starting point for a little machine learning project, I chose the following geometric problem.
We are given a curved triangle in 3D space.
It&amp;rsquo;s specified via its three vertices plus three additional vector-valued coefficients associated to its three edges.
These coefficients are interpreted as control points of a quadratic triangular Bezier surface.
Such representations are commonly used in CAD systems to represent curved surfaces.
Mathematically speaking, we map parameters \((u,v)\) which lie in the parameter-space triangle \( 0 \le u, v;\ u+v \le 1\) to&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
