<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Connect-Zero on cfh::blog</title>
    <link>https://c-f-h.github.io/categories/connect-zero/</link>
    <description>Recent content in Connect-Zero on cfh::blog</description>
    <generator>Hugo -- 0.145.0</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 20 Apr 2025 13:12:41 +0200</lastBuildDate>
    <atom:link href="https://c-f-h.github.io/categories/connect-zero/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Basic Setup and Play</title>
      <link>https://c-f-h.github.io/post/basic-setup-and-play/</link>
      <pubDate>Sun, 20 Apr 2025 13:12:41 +0200</pubDate>
      <guid>https://c-f-h.github.io/post/basic-setup-and-play/</guid>
      <description>&lt;p&gt;Let&amp;rsquo;s get into a bit more technical detail on how our
&lt;a href=&#34;https://c-f-h.github.io/post/connect-zero/&#34;&gt;Connect 4-playing model&lt;/a&gt;
will be set up, and how a basic game loop works.
Throughout all code samples we&amp;rsquo;ll always assume the standard PyTorch imports:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;torch&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;torch.nn&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;nn&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;torch.nn.functional&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;F&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;board-state&#34;&gt;Board state&lt;/h2&gt;
&lt;p&gt;The current board state will be represented by a 6x7 PyTorch &lt;code&gt;int8&lt;/code&gt; tensor,
initially filled with zeros.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;board&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;torch&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;zeros&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;((&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ROWS&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;COLS&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;dtype&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;torch&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;int8&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;device&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;DEVICE&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The board is ordered such that &lt;code&gt;board[0, :]&lt;/code&gt; is the top row.
A non-empty cell is represented by +1 or -1. To simplify things, we always
represent the player whose move it currently is by +1, and the opponent by -1.
This way we don&amp;rsquo;t need any separate state to keep track of whose move it is.
After a move has been made, we simply flip the board by doing&lt;/p&gt;</description>
    </item>
    <item>
      <title>Connect-Zero: Reinforcement Learning from Scratch</title>
      <link>https://c-f-h.github.io/post/connect-zero/</link>
      <pubDate>Sun, 20 Apr 2025 13:12:41 +0200</pubDate>
      <guid>https://c-f-h.github.io/post/connect-zero/</guid>
      <description>&lt;p&gt;For a long time I&amp;rsquo;ve wanted to get deeper into reinforcement learning (RL), and the project
I finally settled on is teaching a neural network model
how to play the classic game &lt;strong&gt;Connect 4&lt;/strong&gt; (&lt;a href=&#34;https://www.youtube.com/watch?v=KN3nohBw_CE&#34;&gt;pretty sneaky, sis!&lt;/a&gt;).
Obviously, the name &amp;ldquo;Connect-Zero&amp;rdquo; is a cheeky nod to AlphaGo Zero
and AlphaZero by DeepMind.
I chose Connect 4 because it&amp;rsquo;s a simple game everyone knows how to play where we can
hope to achieve good results without expensive hardware and high training costs.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Connect 4</title>
      <link>https://c-f-h.github.io/post/connect-4/</link>
      <pubDate>Sun, 20 Apr 2025 09:29:36 +0200</pubDate>
      <guid>https://c-f-h.github.io/post/connect-4/</guid>
      <description>&lt;div id=&#34;game-container1&#34; class=&#34;connect4-container&#34;
    data-human=&#34;1&#34; data-cpu=&#34;2&#34;
    data-random-first-player=&#34;true&#34;
    data-onnx-model=&#34;export.onnx&#34;
&gt;&lt;/div&gt;
&lt;p&gt;The computer opponent is a neural network trained using reinforcement learning.
It was exported to ONNX and now runs right here in your browser.
See &lt;a href=&#34;https://c-f-h.github.io/post/connect-zero/&#34;&gt;Connect-Zero&lt;/a&gt; and the follow-up posts for details.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
