<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>RL on cfh::blog</title>
    <link>https://c-f-h.github.io/tags/rl/</link>
    <description>Recent content in RL on cfh::blog</description>
    <generator>Hugo -- 0.145.0</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 20 Apr 2025 20:29:21 +0200</lastBuildDate>
    <atom:link href="https://c-f-h.github.io/tags/rl/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>The REINFORCE Algorithm</title>
      <link>https://c-f-h.github.io/post/the-reinforce-algorithm/</link>
      <pubDate>Sun, 20 Apr 2025 20:29:21 +0200</pubDate>
      <guid>https://c-f-h.github.io/post/the-reinforce-algorithm/</guid>
      <description>&lt;p&gt;Let&amp;rsquo;s say we have a Connect 4-playing model and we let it
&lt;a href=&#34;https://c-f-h.github.io/post/basic-setup-and-play/&#34;&gt;play a couple of games&lt;/a&gt;.
(We haven&amp;rsquo;t really talked about model architecture until now, so for now just imagine a
simple multilayer perceptron with a few hidden layers which outputs 7 raw logits,
as discussed in the previous post.)&lt;/p&gt;
&lt;p&gt;As it goes in life, our model wins some and loses some. How do we make it
actually learn from its experiences? How does the magic happen?&lt;/p&gt;</description>
    </item>
    <item>
      <title>Connect-Zero: Reinforcement Learning from Scratch</title>
      <link>https://c-f-h.github.io/post/connect-zero/</link>
      <pubDate>Sun, 20 Apr 2025 13:12:41 +0200</pubDate>
      <guid>https://c-f-h.github.io/post/connect-zero/</guid>
      <description>&lt;p&gt;For a long time I&amp;rsquo;ve wanted to get deeper into reinforcement learning (RL), and the project
I finally settled on is teaching a neural network model
how to play the classic game &lt;strong&gt;Connect 4&lt;/strong&gt; (&lt;a href=&#34;https://www.youtube.com/watch?v=KN3nohBw_CE&#34;&gt;pretty sneaky, sis!&lt;/a&gt;).
Obviously, the name &amp;ldquo;Connect-Zero&amp;rdquo; is a cheeky nod to AlphaGo Zero
and AlphaZero by DeepMind.
I chose Connect 4 because it&amp;rsquo;s a simple game everyone knows how to play where we can
hope to achieve good results without expensive hardware and high training costs.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
