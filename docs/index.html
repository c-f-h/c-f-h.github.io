<!DOCTYPE html>
<html lang="en" dir="auto">

<head>
	<meta name="generator" content="Hugo 0.145.0"><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>cfh::blog</title>
<meta name="keywords" content="Blog">
<meta name="description" content="Notes on personal projects">
<meta name="author" content="cfh">
<link rel="canonical" href="https://c-f-h.github.io/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.024295b3c968fbd469a11050839fd375a96747c3a5cff215e7f577090fe610f8.css" integrity="sha256-AkKVs8lo&#43;9RpoRBQg5/TdalnR8Olz/IV5/V3CQ/mEPg=" rel="preload stylesheet" as="style">
<link rel="icon" href="https://c-f-h.github.io/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://c-f-h.github.io/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://c-f-h.github.io/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://c-f-h.github.io/apple-touch-icon.png">
<link rel="mask-icon" href="https://c-f-h.github.io/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" type="application/rss+xml" href="https://c-f-h.github.io/index.xml">
<link rel="alternate" hreflang="en" href="https://c-f-h.github.io/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript><head>
  
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>
<script>
  MathJax = {
    tex: {
      displayMath: [['\\[', '\\]'], ['$$', '$$']],  
      inlineMath: [['\\(', '\\)']]                  
    },
    loader:{
      load: ['ui/safe']
    },
  };
</script>
  
  
  
</head><meta property="og:url" content="https://c-f-h.github.io/">
  <meta property="og:site_name" content="cfh::blog">
  <meta property="og:title" content="cfh::blog">
  <meta property="og:description" content="Welcome! This is a blog on some of my side projects. My background is in computational mathematics, numerical linear algebra and some computational geometry, but these projects lean heavily towards machine learning.
I use LLM-based tools quite liberally on these side projects for brainstorming and implementation, but the writing on this blog is all my own.
Projects:
Connect-Zero: Reinforcement Learning from Scratch (intro post) The Triangle Project (intro post) Recent posts">
  <meta property="og:locale" content="en-us">
  <meta property="og:type" content="website">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="">
<meta name="twitter:description" content="Notes on personal projects">

<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "Organization",
  "name": "cfh::blog",
  "url": "https://c-f-h.github.io/",
  "description": "Notes on personal projects",
  "logo": "https://c-f-h.github.io/favicon.ico",
  "sameAs": [
      "https://github.com/c-f-h/"
  ]
}
</script>
</head>

<body class="list" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://c-f-h.github.io/" accesskey="h" title="cfh::blog (Alt + H)">cfh::blog</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)" aria-label="Toggle theme">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://c-f-h.github.io/categories/" title="categories">
                    <span>categories</span>
                </a>
            </li>
            <li>
                <a href="https://c-f-h.github.io/tags/" title="tags">
                    <span>tags</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main"> 
<div class="post-content"><p>Welcome! This is a blog on some of my side projects.
My background is in computational mathematics, numerical linear algebra
and some computational geometry, but these projects lean heavily
towards machine learning.</p>
<p>I use LLM-based tools quite liberally on these side projects for
brainstorming and implementation, but the writing on this blog is
all my own.</p>
<p>Projects:</p>
<ul>
<li><a href="/categories/connect-zero/">Connect-Zero: Reinforcement Learning from Scratch</a> (<a href="/post/connect-zero/">intro post</a>)</li>
<li><a href="/categories/the-triangle-project/">The Triangle Project</a> (<a href="/post/the-triangle-problem/">intro post</a>)</li>
</ul>
<h2 id="recent-posts">Recent posts<a hidden class="anchor" aria-hidden="true" href="#recent-posts">#</a></h2>


</div>

<article class="post-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">Implementing and Evaluating REINFORCE with Baseline
    </h2>
  </header>
  <div class="entry-content">
    <p>Having introduced REINFORCE with baseline on a conceptual level, let’s implement it for our Connect 4-playing CNN model.
Runnable example code for this post is at connect-zero/train/example3-rwb.py.
Adding the value head In the constructor of the Connect4CNN model class, we set up the new network for estimating the board state value \(v(s)\) which will consume the same 448 downsampled features that the policy head receives:
self.value_head = nn.Sequential( nn.Linear(64 * 7, 64), nn.ReLU(), nn.Linear(64, 64), nn.ReLU(), nn.Linear(64, 1), nn.Tanh() ) It’s very similar in structure to the MLP policy head, with some minor differences:
...</p>
  </div>
  <footer class="entry-footer"><span title='2025-05-01 23:05:00 +0200 +0200'>May 1, 2025</span>&nbsp;·&nbsp;cfh</footer>
  <a class="entry-link" aria-label="post link to Implementing and Evaluating REINFORCE with Baseline" href="https://c-f-h.github.io/post/implementing-rwb/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">REINFORCE with Baseline
    </h2>
  </header>
  <div class="entry-content">
    <p>In the previous post, we introduced a stronger model but observed that it’s quite challenging to achieve a high level of play with basic REINFORCE, due to the high variance and noisy gradients of the algorithm which often lead to unstable learning and slow convergence. Our first step towards more advanced algorithms is a modification called “REINFORCE with baseline” (see, e.g., Sutton et al. (2000)).
The value network Given a board state \(s\), recall that our model currently outputs seven raw logits which are then transformed via softmax into the probability distribution \(p(s)\) over the seven possible moves. Many advanced algorithms in RL assume that our network also outputs a second piece of information: the value \(v(s)\), a number between -1 and 1 which, roughly speaking, gives an estimate of how confident the model is in winning from the current position.
...</p>
  </div>
  <footer class="entry-footer"><span title='2025-04-29 08:42:00 +0200 +0200'>April 29, 2025</span>&nbsp;·&nbsp;cfh</footer>
  <a class="entry-link" aria-label="post link to REINFORCE with Baseline" href="https://c-f-h.github.io/post/reinforce-with-baseline/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">Model Design for Connect 4
    </h2>
  </header>
  <div class="entry-content">
    <p>With the fearsome RandomPunisher putting our first Connect 4 toy model in its place, it’s time to design something that stands a chance.
A design based on CNNs It’s standard practice for board-game playing neural networks to have at least a few convolutional neural network (CNN) layers at the initial inputs. This shouldn’t come as a surprise: the board is a regular grid, much like an image, and CNNs are strong performers in image processing. In our case, it will allow the model to learn features like “here are three of my pieces in a diagonal downward row” which are then automatically applied to every position on the board, rather than having to re-learn these features individually at each board position.
...</p>
  </div>
  <footer class="entry-footer"><span title='2025-04-28 22:30:00 +0200 +0200'>April 28, 2025</span>&nbsp;·&nbsp;cfh</footer>
  <a class="entry-link" aria-label="post link to Model Design for Connect 4" href="https://c-f-h.github.io/post/model-design/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">Introducing a Benchmark Opponent
    </h2>
  </header>
  <div class="entry-content">
    <p>Last time we saw how the entropy bonus enables self-play training without running into policy collapse. However, the model we trained was quite small and probably not capable of very strong play. Before we dive into the details of an improved model architecture, it would be very helpful to have a decent, fixed benchmark to gauge our progress.
A benchmark opponent The only model with fixed performance we have right now is the RandomPlayer from the basic setup post. Obviously, that’s not a challenging bar to clear. But it turns out that with some small tweaks, we can turn the fully random player into a formidable opponent for our starter models.
...</p>
  </div>
  <footer class="entry-footer"><span title='2025-04-26 09:50:00 +0200 +0200'>April 26, 2025</span>&nbsp;·&nbsp;cfh</footer>
  <a class="entry-link" aria-label="post link to Introducing a Benchmark Opponent" href="https://c-f-h.github.io/post/random-punisher/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">Entropy Regularization
    </h2>
  </header>
  <div class="entry-content">
    <p>Based on our discussion on entropy, our plan is to implement entropy regularization via an entropy bonus in our loss function.
Implementing the entropy bonus The formula for entropy which we have to implement,
\[H(p) = -\sum_{i=1}^{C} p_i \log p_i,\]is simple enough: multiply the probabilities for the seven possible moves with their log-probabilities, sum and negate. However, there is one numerical problem we have to worry about: masking out an illegal move \(i\) leads to a zero probability \(p_i=0\) and a log-probability \(\log p_i = -\infty\). However, due to the rules of IEEE 754 floating point numbers, multiplying zero with \(\pm\infty\) is undefined and therefore results in NaN (not a number). For the entropy formula, however, the contribution should be 0.
...</p>
  </div>
  <footer class="entry-footer"><span title='2025-04-24 20:15:00 +0200 +0200'>April 24, 2025</span>&nbsp;·&nbsp;cfh</footer>
  <a class="entry-link" aria-label="post link to Entropy Regularization" href="https://c-f-h.github.io/post/entropy-regularization/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">On Entropy
    </h2>
  </header>
  <div class="entry-content">
    <p>The last time, we ran our first self-play training loop on a simple MLP model and observed catastrophic policy collapse. Let’s first understand some of the math behind what happened, and then how to combat it.
What is entropy? Given a probability distribution \(p=(p_1,\ldots,p_C)\) over a number of categories \(i=1,\ldots,C\), such as the distribution over the columns our Connect 4 model outputs for a given board state, entropy measures the “amount of randomness” and is defined as1
...</p>
  </div>
  <footer class="entry-footer"><span title='2025-04-23 20:57:00 +0200 +0200'>April 23, 2025</span>&nbsp;·&nbsp;cfh</footer>
  <a class="entry-link" aria-label="post link to On Entropy" href="https://c-f-h.github.io/post/on-entropy/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">A First Training Run and Policy Collapse
    </h2>
  </header>
  <div class="entry-content">
    <p>With the REINFORCE algorithm under our belt, we can finally attempt to start training some models for Connect 4. However, as we’ll see, there are still some hurdles in our way before we get anywhere. It’s good to set your expectations accordingly because rarely if ever do things go smoothly the first time in RL.
A simple MLP model As a fruitfly of Connect 4-playing models, let’s start with a simple multilayer perceptron (MLP) model that follows the model protocol we outlined earlier: that means that it has an input layer taking a 6x7 int8 board state tensor, a few simple hidden layers consisting of just a linear layer and a ReLU activation function each, and an output layer of 7 neurons without any activation function—that’s exactly what we meant earlier when we said that the model should output raw logits.
...</p>
  </div>
  <footer class="entry-footer"><span title='2025-04-21 17:45:00 +0200 +0200'>April 21, 2025</span>&nbsp;·&nbsp;cfh</footer>
  <a class="entry-link" aria-label="post link to A First Training Run and Policy Collapse" href="https://c-f-h.github.io/post/policy-collapse/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">The REINFORCE Algorithm
    </h2>
  </header>
  <div class="entry-content">
    <p>Let’s say we have a Connect 4-playing model and we let it play a couple of games. (We haven’t really talked about model architecture until now, so for now just imagine a simple multilayer perceptron with a few hidden layers which outputs 7 raw logits, as discussed in the previous post.)
As it goes in life, our model wins some and loses some. How do we make it actually learn from its experiences? How does the magic happen?
...</p>
  </div>
  <footer class="entry-footer"><span title='2025-04-20 20:29:21 +0200 +0200'>April 20, 2025</span>&nbsp;·&nbsp;cfh</footer>
  <a class="entry-link" aria-label="post link to The REINFORCE Algorithm" href="https://c-f-h.github.io/post/the-reinforce-algorithm/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">Basic Setup and Play
    </h2>
  </header>
  <div class="entry-content">
    <p>Let’s get into a bit more technical detail on how our Connect 4-playing model will be set up, and how a basic game loop works. Throughout all code samples we’ll always assume the standard PyTorch imports:
import torch import torch.nn as nn import torch.nn.functional as F Board state The current board state will be represented by a 6x7 PyTorch int8 tensor, initially filled with zeros.
board = torch.zeros((ROWS, COLS), dtype=torch.int8, device=DEVICE) The board is ordered such that board[0, :] is the top row. A non-empty cell is represented by &#43;1 or -1. To simplify things, we always represent the player whose move it currently is by &#43;1, and the opponent by -1. This way we don’t need any separate state to keep track of whose move it is. After a move has been made, we simply flip the board by doing
...</p>
  </div>
  <footer class="entry-footer"><span title='2025-04-20 15:35:41 +0200 +0200'>April 20, 2025</span>&nbsp;·&nbsp;cfh</footer>
  <a class="entry-link" aria-label="post link to Basic Setup and Play" href="https://c-f-h.github.io/post/basic-setup-and-play/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">Connect-Zero: Reinforcement Learning from Scratch
    </h2>
  </header>
  <div class="entry-content">
    <p>For a long time I’ve wanted to get deeper into reinforcement learning (RL), and the project I finally settled on is teaching a neural network model how to play the classic game Connect 4 (pretty sneaky, sis!). Obviously, the name “Connect-Zero” is a cheeky nod to AlphaGo Zero and AlphaZero by DeepMind. I chose Connect 4 because it’s a simple game everyone knows how to play where we can hope to achieve good results without expensive hardware and high training costs.
...</p>
  </div>
  <footer class="entry-footer"><span title='2025-04-20 13:12:41 +0200 +0200'>April 20, 2025</span>&nbsp;·&nbsp;cfh</footer>
  <a class="entry-link" aria-label="post link to Connect-Zero: Reinforcement Learning from Scratch" href="https://c-f-h.github.io/post/connect-zero/"></a>
</article>
<footer class="page-footer">
  <nav class="pagination">
    <a class="next" href="https://c-f-h.github.io/page/2/">Next&nbsp;&nbsp;»
    </a>
  </nav>
</footer>
    </main>
    
<footer class="footer">
        <span>&copy; 2025 <a href="https://c-f-h.github.io/">cfh::blog</a></span> · 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
</body>

</html>
